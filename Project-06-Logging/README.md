ğŸ“˜ Project 06 â€“ Kubernetes Logging with EFK Stack

This project sets up centralized logging in Kubernetes using the EFK stack:

Elasticsearch â†’ stores logs

Fluentd â†’ log collector and forwarder

Kibana â†’ visualization and search

ğŸ“‚ Project Structure
project-06-logging/
â”‚â”€â”€ elasticsearch-deployment.yaml
â”‚â”€â”€ fluentd-daemonset.yaml
â”‚â”€â”€ kibana-deployment.yaml
â”‚â”€â”€ namespace.yaml
â”‚â”€â”€ README.md

ğŸš€ Steps to Deploy
1ï¸âƒ£ Create a Namespace
kubectl create ns logging

2ï¸âƒ£ Deploy Elasticsearch
kubectl apply -f elasticsearch-deployment.yaml -n logging


âš ï¸ Note: Elasticsearch is memory-hungry. Set ES_JAVA_OPTS and resource limits:

env:
- name: ES_JAVA_OPTS
  value: "-Xms512m -Xmx512m"
resources:
  requests:
    memory: "1Gi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "1"

3ï¸âƒ£ Deploy Fluentd (DaemonSet)
kubectl apply -f fluentd-daemonset.yaml -n logging


Fluentd will run on each node and forward logs to Elasticsearch.

4ï¸âƒ£ Deploy Kibana
kubectl apply -f kibana-deployment.yaml -n logging

5ï¸âƒ£ Verify Pods
kubectl get pods -n logging

6ï¸âƒ£ Access Kibana

Forward Kibana service to localhost:

kubectl port-forward svc/kibana 5601:5601 -n logging


Open â†’ http://localhost:5601

ğŸ” Expected Output

kubectl get pods -n logging should show Running pods for elasticsearch, fluentd, and kibana.

In Kibana, you can configure an index pattern logstash-* to start viewing logs from Kubernetes pods.

ğŸ›  Troubleshooting

If Elasticsearch pod is OOMKilled â†’ increase memory limits or reduce JVM heap (ES_JAVA_OPTS).

If Kibana shows no data â†’ ensure Fluentd DaemonSet is running and pushing logs.

Check logs:

kubectl logs <fluentd-pod> -n logging
kubectl logs <elasticsearch-pod> -n logging

ğŸ¯ Learning Outcomes

âœ” Understand how logs flow in Kubernetes from pods â†’ Fluentd â†’ Elasticsearch â†’ Kibana
âœ” Learn how to configure resource limits to avoid OOMKilled issues
âœ” Gain hands-on with one of the most widely used logging stacks in production